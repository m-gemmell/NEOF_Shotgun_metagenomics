# Genome binning {#binning}
<center>
![](figures/yarn_binning.png){style="width:400px"}
</center>

A metagenome assembly consists of contigs from many different genomes. At this stage we don't know which contigs are from which species. We could try to taxonomically classify each contig but there are 2 problems with this approach:

1. Some contigs may be misclassified which can lead to multiple contigs from the same genome/organism being classified as various taxa.
2. Databases are incomplete and so some contigs will not be classified at all (microbial dark matter).

To alleviate these issues genomic binning can be carried out. This will cluster contigs into bins based on:

- __Coverage__: Contigs with similar coverage are more likely to be from the same genome.
- __Composition__: Contigs with similar GC content are more likely to belong to the same genome.

Genomic binning has been used to discover many new genomes. Additionally, it makes downstream analyses quicker as the downstream steps will be carried out on the sets of bins rather than on one large metagenome assembly.

Binning produces "bins" of contigs of various quality (e.g. draft, complete). These bins are also known as MAGs (Metagenome-assembled genomes). In other words a MAG is a single assembled genome that was assembled with other genomes in a metagenome assembly but later separated from the other assemblies. The term MAG  has been adopted by the GSC (Genomics Standards Consortium).

It is recommended to ensure you do not have a poor quality metagenome assembly. Binning requires contigs of good length and good coverage. Extremely low coverage and very short contigs will be excluded from binning.

## MetaBAT2
<center>
![](figures/bat.png){style="width:200px"}
</center>

We will use `MetaBAT2` for our genome binning. It has three major upsides that makes it very popular:

1. It has very reliable default parameters meaning virtually no parameter optimisation is required.
2. It performs very well amongst genome binners.
3. It is computationally efficient compared to other binners (requires less RAM, cores etc.)

Make a new directory and move into it.

```{bash eval=FALSE}
#Make directory
mkdir -p ~/7-Binning/K1
#Move into it
cd ~/7-Binning/K1
```

### MetaBAT2: depth calculation
<center>
![](figures/submarine.png){style="width:100px"}
</center>

To carry out effective genome binning `MetaBAT2` uses coverage information of the contigs. To calculate depth we need to align the reads to the metagenome assembly.

#### Index assembly {-}

For the alignment we will use `bwa`. We need to index our assembly file prior to alignment.

```{bash eval=FALSE}
bwa index ~/6-Assembly/K1/final.contigs.fa
```

#### Alignment {-}

Next we will align our trimmed paired reads we used to create the stitched reads. We will carry this out with the `bwa mem` command. `bwa mem` is a good aligner for short reads. If you are using long reads (PacBio or Nanopore) `minimap2` will be more appropriate.

```{bash eval=FALSE}
bwa mem ~/6-Assembly/K1/final.contigs.fa \
~/2-Trimmed/K1_R1.fq.gz ~/2-Trimmed/K1_R2.fq.gz > \
K1.sam
```

#### Sam to sorted bam {-}

After alignment we need to get the file ready for the contig depth summarisation step. This requires converting the `sam` file to a `bam` (binary form of a `sam` file) file and then sorting the `bam` file.

```{bash eval=FALSE}
# Convert sam to bam file
samtools view -bu K1.sam > K1.bam
# Created sorted bam file
samtools sort K1.bam > K1.sort.bam
```

#### Summarise depths {-}

Now we can summarise the contig depths from the sorted `bam` files with `MetaBAT2`'s `jgi_summarize_bam_contig_depths` command.

```{bash eval=FALSE}
jgi_summarize_bam_contig_depths --outputDepth K1.depth.txt K1.sort.bam
```

#### View summary depth {-}

You can have a look at the depth file and you will notice there are many contigs with low coverage (<10) and of short length (<1500).

```{bash eval=FALSE}
less K1.depth.txt
```

To get a better look we will open the file in `R` and look at a summary of the file's table.

Activate `R`:

```{bash eval=FALSE}
R
```

Now in `R` we will read in the file and get a `summary()` of it.

```{r eval=FALSE}
#Read in the table as an object called df (short for data frame)
#We want the first row to be the column names (header=TRUE)
#We do not want R to check the column names and "fix" them (check.names=FALSE)
df <- read.table("K1.depth.txt", header=TRUE, check.names=FALSE)
#Create a summary of the data
summary(df)
```

The last command gave us summary information of all the columns. This includes the minimum, maximum, mean, median, and Inter-Quartile Range (IQR) values. 

We can see the values of the `contigLen` and `totalAvgDepth` are very low. However, this is most likely due to a bunch of short and low coverage contigs which will be ignored by `MetaBAT2`. Therefore we will remove rows with information on contigs shorter than 1500 and rerun the summary. `MetaBAT2`'s documentation dictates the minimum contig length should be >=1500 with its default being 2500.

```{r eval=FALSE}
#Set the new object "df_min1500len" as all rows
#where the value in the column "contigLen" of "df"
#Is greater than or equal to 1500
df_min1500len <- df[df$contigLen >= 1500,]
#Summary of our new data frame
summary(df_min1500len)
```

That is looking better. The minimum average coverage for `MetaBAT2` is 1 and our minimum value is 2.700 with a maximum of 93.285 (your values may differ slightly). Now you can quit R and continue.

```{r eval=FALSE}
#quit R
q()
#On the prompt to save your workspace press "n" and then enter.
```

__Note__: One of the reasons for our short contigs is that we only used a subset of our sequencing dataset for this tutorial due to time concerns.

### MetaBAT2: run
<center>
![](figures/play_orange.png){style="width:100px"}
</center>

With our assembly and its depth information we can run `MetaBAT2` for binning.

```{bash eval=FALSE}
#make a diretcory for the bins
mkdir bins
#Run MetaBAT2
metabat2 \
--inFile ~/6-Assembly/K1/final.contigs.fa \
--outFile bins/K1 \
--abdFile K1.depth.txt \
--minContig 1500
```

#### Parameters {-}
<center>
![](figures/parameter_orange.png){style="width:100px"}
</center>

- `--inFile`: Input metagenome assembly fasta file.
- `--outFile`: Prefix of output files.
- `--abdFile`: Base depth file.
- `--minContig`: Minimum size of contigs to be used for binning.
  - The default is 2500.
  - We used the minimum value of 1500 as we are using tutorial data. We recommend using the default in your own analysis.

### MetaBAT2: output
<center>
![](figures/output_file_orange.png){style="width:100px"}
</center>

List the contents of the output directory and you'll see there is 1 fasta file with the prefix of `K1`. This is a bin that will hopefully contain 1 MAG (Metagenome-Assembled Genome). In your future analysis you may get many bins, each hopefully only having one MAG.

```{bash eval=FALSE}
ls bins
```

## CoCoPyE

`CoCoPyE` is a useful tool to assess the quality of assembled microbial genomes. This can be used on assemblies produced from single cell, single isolate, or metagenome data. Additionally, it can be used to identify bins that are likely candidates for merging. This occurs when one genome has been separated into different bins.

FINISH EXPLANATION BELOW


`CoCoPyE` estimates quality of a genome by estimating completeness and contamination. It carries this out in 2 stages:

1. __Extraction__: 
2. __Transformation__: 

<center>
![](figures/cocopye_workflow.jpeg){style="width: 800px; border-radius: 5px; border: white 5px solid"}
</center>

CoCoPyE publications: https://academic.oup.com/gigascience/article/doi/10.1093/gigascience/giae079/7841111

### CoCoPyE: Mamba
<center>
![](figures/mamba_logo.png){style="width: 200px; border-radius: 5px"}
</center>

Due to program version conflicts we will use the `CoCoPyE` conda environment for this section.

Open a new terminal and activate the `CoCoPyE` environment.

```{bash eval=FALSE}
. usecocopye
```

Ensure you are in the correct directory.

```{bash eval=FALSE}
cd ~/7-Binning/K1/
```

### CoCoPyE: run
<center>
![](figures/play_black.png){style="width:100px"}
</center>

`CoCoPyE` has one main command to predict bin quality: `CoCoPyE run`. 

Run the `CoCoPyE` command (this will take a while):

```{bash eval=FALSE}
CoCoPyE run \
-t 12 \
-i bins/ \
-o cocopye_output.csv
```

#### Parameters {-}
<center>
![](figures/parameter_black.png){style="width:100px"}
</center>

- `-t` : Number of threads/cores/CPUs to utilise for the process.
- `-i` : Input directory containing the bins in FASTA format.
- `-o` : Output file (more info below)

Other options include:

- `--file-extensions` : The allowed file extensions for input files within the input directory.
  - The default is `fasta,fna,fa`. Our bin files produced from `MetaBAT2` have the file extension/suffix of `.fa` so the default works.
- `-v` : The output file verbosity. 
  - Values are: `standard` (default), `extended`, and `full`.
  - More information on the output below.
  

### CoCoPyE: output
<center>
![](figures/output_file_black.png){style="width:100px"}
</center>

As we have only used a subset of data the results are not very good. We'll therefore look at premade results. 
These premade results were produced using the entire K1 dataset. 
First you will need to copy them.

```{bash eval=FALSE}
cd ~/7-Binning
mkdir K1_fullset
cd K1_fullset
ln -s /pub14/tea/nsc206/NEOF/Shotgun_metagenomics/binning/K1_fullset/* .
```

Now we can look at the results table that is in your current directory.

```{bash eval=FALSE}
#Use tr to tranform commas (,) to tabs (\t)
#This makes it easier to visually parse the columns
cat cocopye_output.csv | tr "," "\t" | less
```

`r hide("CoCoPye statistics definitions")`
Output columns when `-v` set to `standard` (also the default)

- `bin`: Name of the input bin (filename excluding file extension)
- `completeness`: Completeness value between 0 and 1
- `contamination`: Contamination value between 0 and 1
- `method`: Either markers or markers + neural network
- `taxonomy`: Taxonomy estimate based on a consensus between the nearest neighbors
- `taxonomy_level`: Rank of the taxonomy estimate
- `notes`: Additional notes (currently this is always empty, but we might add some notes in the future)

Please see the full list of statistics definitions from [CoCoPyE wiki](https://github.com/gobics/cocopye/wiki/Output). This includes the defintions when `-v` is set to `extended` or `full`.
`r unhide()`

### CoCoPyE: Quality score

One quick way to calculate the overall quality of a bin is with the following equation:

$$
q = comp - (5 * cont)
$$
Where:

- __q__ = Overall quality
- __comp__ = Completeness
- __cont__ = Contamination

A score of at least 70-80% (i.e. 0.7 to 0.8) would be the aim, with a maximum/perfect value being 100% (100% completeness, 0% contamination). Therefore let us calculate this for the bins with some bash and `awk` scripting.

__Note__: Values will range from:

- 100% (i.e. 1): 1 Completeness - (5 * 0 Contamination)
- -500% (i.e. -5): 0 Completeness - (5 * 1 Contamination)

#### Quality file {-}

We will create a new file with only the quality information. We'll start by making a file with only a header.

```{bash eval=FALSE}
echo "quality" > MAGS_quality.csv
```

#### Calculate quality with awk {-}

Next is the most complicated command. We will be calculating the Overall quality (see calculation above) for each row except the header row.

We will be using a complicated linux based language called `awk`. This is very useful as it can carry out calculations on columns or as `awk` calls them, __fields__.

As this is new and complicated we will build up our command step by step.

##### Extract fields/columns {-}

__The first step__ is to extract the completeness and contamination fields/columns.

```{bash eval=FALSE}
awk -F, '{print $2,$3}' cocopye_output.csv
```

- `-F,`: Indicates the input fields are separated by commas (`,`).
- `''`: All the `awk` options are contained within the quotes.
- `{}`: We can supply a function to `awk` within the braces.
- `print $2,$3`: This function instructs `awk` to print the 2nd (completeness) and 3rd (contamination) fields. It is common to put commas (`,`) between fields if printing multiple fields.
- `MAGS_checkm.csv`: Our last parameter is the input file. We are not changing the contents of the file, only printing information to screen/stdout.

##### Ignore header {-}

__We do not want the header__ in our calculation so we will add an extra `awk` option.

```{bash eval=FALSE}
awk -F, 'NR>1 {print $2,$3}' cocopye_output.csv
```

- `NR>1`: `NR` stands for number of records. Rows are called records in `awk`. Therefore `NR>1` means `awk` will only carry out the functions on the records numbered greater than 1. I.e. skip row 1, the header row.

##### Calculate quality {-}

__The next step__ is to carry out the overall quality calculation and append the information to the "MAGS_quality.csv" file.

```{bash eval=FALSE}
awk -F, 'NR>1 {print $2 - (5 * $3)}' cocopye_output.csv
```

Our new function, `{print $12 - (5 * $13)}`, carries out the overall quality calculation and prints it for each record/row except the first (`NR>1`).

You will notice that we have values that equal 4.
Let us fix that.

##### Fix values {-}

Some quality values come out as 4.
This is not correct and comes about as the completeness and contamination values have been set to -1 (-1 - (5 * -1) = 4).
If you look at the file `cocopye_output.csv` you will notice the bins with -1 values have the `rejected` for their `method` value.
We will therefore change these quality values to the lowest possible value of -5 (0 - (5 * 1) = -5).

```{bash eval=FALSE}
awk -F, 'NR>1 {print $2 - (5 * $3)}' cocopye_output.csv | \
sed "s/^4$/-5/"
```

In this case we [pipe (`|`)](https://neof-workshops.github.io/Unix_nxcdf7/Course/12-Advanced_linux_practice.html#pipes) our output to [`sed`](https://neof-workshops.github.io/Unix_nxcdf7/Course/12-Advanced_linux_practice.html#sed) to substitute lines that start with (`^`) and end with (`$`) the same `4` with `-5`.

In other words we replace lines that only contain a 4 with a -5.

##### Append to quality file {-}

Finally we can append the quality values to our `MAGS_quality.csv` file.

```{bash eval=FALSE}
awk -F, 'NR>1 {print $2 - (5 * $3)}' cocopye_output.csv | \
sed "s/^4$/-5/" >> MAGS_quality.csv
```

In the above case we use `>>` to append the infomration to the file `MAGS_quality.csv`. We append because we want to retain the header we added to the file earlier.

You can view the file to ensure it worked. The first and second values should be 0.9838 and 0.493

```{bash eval=FALSE}
less MAGS_quality.csv
```

#### Add quality to the checkm results file {-}

Now we can combine the files "cocopye_output.csv" and "MAGS_quality.csv" with the `paste` command. The `-d ","` option indicates the merged files will be separated by commas (`,`), matching the column separation in "MAGS_checkm.csv".

```{bash eval=FALSE}
paste -d "," cocopye_output.csv MAGS_quality.csv > cocopye_quality.csv
```

### CheckM: MCQs
<center>
![](figures/question_bubble_blue.png){style="width:100px"}
</center>

Viewing the file "MAGS_checkm_quality.csv" attempt the below questions.

__Tip__: You can use the `cut` command to look at specific columns. For example:

```{bash eval=FALSE}
#look at the "bin" and "quality" columns
#Convert the printed output's commas to tabs for readability
cut -d "," -f 1,8 cocopye_quality.csv | tr "," "\t"
```

```{r, echo = FALSE}
opts_p <- c("__Bacteria__", answer="__Bacteroides__", "__Lachnospiraceae__")
```
1. What lineage was assigned to bin __K1.1__? `r longmcq(opts_p)`

```{r, echo = FALSE}
opts_p <- c("__Bacteria__", "__Bacteroides__", answer="__Lachnospiraceae__")
```
2. What lineage was assigned to bin __K1.22__? `r longmcq(opts_p)`

```{r, echo = FALSE}
opts_p <- c(answer="__Bacteria__", "__Bacteroides__", "__Lachnospiraceae__")
```
3. What lineage was assigned to bin __K1.8__? `r longmcq(opts_p)`

```{r, echo = FALSE}
opts_p <- c("__0.0202__", answer="__0.6724__", "__0.9769__")
```
4. What is the quality value of __K1.1__? `r longmcq(opts_p)`

```{r, echo = FALSE}
opts_p <- c("__0.0202__", "__0.6724__", answer="__0.9769__")
```
5. What is the completeness value of __K1.30__? `r longmcq(opts_p)`

```{r, echo = FALSE}
opts_p <- c(answer="__0.0202__", "__0.6724__", "__0.9769__")
```
6. What is the contamination value of __K1.12__ bin? `r longmcq(opts_p)`

```{r, echo = FALSE}
opts_p <- c("__K1.20__", "__K1.26__", answer="__K1.22__")
```
7. Which bin has the highest quality value (98.38%)? `r longmcq(opts_p)`

```{r, echo = FALSE}
opts_p <- c(answer="__K1.20__", "__K1.26__", "__K1.22__")
```
8. Which bin has the quality value of -2.9215? `r longmcq(opts_p)`

```{r, echo = FALSE}
opts_p <- c("__K1.20__", answer="__K1.26__", "__K1.22__")
```
9. Which bin has the highest completeness value (98.59%)? `r longmcq(opts_p)`

## Binning summary
<center>
![](figures/sum_black.png){style="width:100px"}
</center>

It is always useful to know the quality of your bins so you know which are more reliable than others. With that information you can be more or less certain when concluding your findings.

We have some good quality bins. However, the best bins would only have one genome. Ultimately binning is trying to separate all the genomes from each other. A better metagenome assembly would most likely have led to better binning.