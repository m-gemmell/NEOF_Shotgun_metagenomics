[["01-Shotgun_metagenomics.html", "Shotgun Metagenomics Chapter 1 Introduction", " Shotgun Metagenomics Sam Haldenby and Matthew Gemmell 2021-04-22 Chapter 1 Introduction This practical session aims to introduce you to the analysis of Shotgun metagenomic data. The topics covered are: Overview Raw data Trimming data Taxonomic profiling Functional profiling Metagenome assembly Gene prediction Functional annotation Co-assembly Comparative analysis "],["02-Overview.html", "Chapter 2 Overview 2.1 What is metagenomics? 2.2 Why metagenomics? 2.3 Metagenomics vs Metagenetics 2.4 Tutorial overview", " Chapter 2 Overview 2.1 What is metagenomics? Meta /mt/ : prefix meaning higher or beyond Metagenomics is the study of genes and genetic material recovered from environmental samples (whether from the sea, soil, human gut, or anywhere else you can imagine). Unlike genomics, metagenomics deals with a multitude of usually diverse species rather than focussing on a single species/genome. 2.2 Why metagenomics? Microbes exist virtually everywhere on Earth, even in some of the most seemingly hostile environments. Every process on our planet is influenced in some way by the actions of microbes, and all higher organisms are intrinsically associated with microbial communities. While much can be learned from studying the genome of a single microbial species in isolation, it does not provide us with any information regarding that species neighbours, i.e. what else is in its natural environment? Metagenomics offers a top-down approach which allows researchers to investigate and understand interactions between species in different environments, thus providing a much broader and complete picture. 2.3 Metagenomics vs Metagenetics Broadly speaking, there are two families of metagenomic analysis: Amplicon-based: This utilises sequencing data generated from amplified marker sequences, for example, regions of the 16S rRNA. Sequences are clustered together and taxonomically assigned to estimate the species abundance in a sample. This is sometimes referred to metagenetics, as it does not consist of any genomic analysis beyond the marker gene regions. Shotgun: This utilises sequencing data generated from random fragments from total genomic DNA from environmental samples, rather than targeting specific genes. This approach allows for not only species abundance determination but direct functional analysis, too, due to having information on a wide range of genetic data sampled from the population. This is sometimes referenced as metagenomics, as it involves genome-wide analyses. Shotgun metagenomics is the focus of this practical session. 2.4 Tutorial overview 2.4.1 Basics This tutorial and practical session focuses on performing a range of metagenomic analyses using shotgun sequence data from the Illumina platforms. The analyses discussed here are by no means exhaustive and are instead intended to provide a sample of what can be done with a metagenomic dataset. Virtually the entire tutorial will be carried out on the command line, which you will hopefully now be more comfortable with. 2.4.2 Structure We prefer to allow people to work at a pace that they are comfortable with rather than ensuring that everyone is at the same point of the tutorial at the same time. So, there will be no instructor telling you what to type and click: Instead, everything you require to carry out the practical is written in the document. Take your time; its important to spend some time understanding why you are running the commands, rather than simply typing them out. If at any point you are having trouble or have a question, let one of us know and well provide 1-to-1 assistance. 2.4.3 Content This practical is broken up into the following broad sections. Raw data: We will first link to a dataset that we have downloaded for this tutorial. We will take a quick look at what the sequence files look like and briefly discuss the origin of the samples. Trimming data: This entails preprocessing our data to ensure that it is of good quality. Taxonomic profiling: We will analyse the dataset to determine the species abundance in each sample. Following this, we will visualise the data and compare the samples. Functional profiling: We will analyse the dataset to determine the pathway abundance and completeness in each sample. Following this, we will visualise the data and compare the samples. Metagenome assembly: Here, we will move away from just analysing the reads directly and will assemble the metagenome into contigs. Prior to this, we will stitch the reads together to ensure we get the best assembly possible. Gene prediction: We will take our metagenome assembly, search for genes Functional annotation: and then functionally annotate them with information from various databases. We will then visualise some of the output. Co-assembly: Instead of just looking at the functional composition of one metagenome sample, we will discuss methods of combining all samples to carry out a co-assembly and then obtain normalised gene coverage statistics for use in comparative analyses between samples. Comparative analysis: Using our data from the previous step, we will look at a couple of different ways of comparing the functional profiles of our samples All the analyses here are just examples of how you could interrogate a metagenomic dataset: There are, of course, many other ways to tackle such a set. Dont worry if you dont manage to finish the whole practical! The more commonly used analyses have been put at the front of the practical (Section 1-4) with the less standard ones being placed towards the end. We will provide you with all of the intermediate and results files on request. "],["03-Start.html", "Chapter 3 Before we start", " Chapter 3 Before we start During this practical you will use a number of installed programs and scripts. To ensure that the system knows where to look for the scripts, run the following command: source /pub21/sam/metagenomicsWorkshop2019.sh Also, theres a chance youre currently not in your home directory, so lets make sure you are with the following command: cd ~ "],["04-Raw_data.html", "Chapter 4 Raw data 4.1 Obtaining the data 4.2 Checking quality control", " Chapter 4 Raw data The very first thing we need to do is to obtain a dataset to work with. The European Bioinformatics Institute (EBI) provides an excellent metagenomics resource (https://www.ebi.ac.uk/metagenomics/) which allows users to download publicly available metagenomic and metagenetic datasets. Have a browse of some of the projects by selecting one of the biomes on this page. We have selected a dataset from this site that consists of DNA shotgun data generated from 24 human faecal samples. 12 of these samples are from subjects who were fed a western diet and 12 are from subjects who were fed a Korean diet. This dataset comes from the EBI metagenomics resource (https://www.ebi.ac.uk/metagenomics/projects/ERP005558). 4.1 Obtaining the data First, we need to create a directory to put the data in and then change directory to it. mkdir 1-Raw cd 1-Raw Now we can generate a symbolic link (i.e. shortcut) to the raw sequence data files, which will appear in the current directory: linkFiles All that this command did is run a script which creates a symbolic link (like a shortcut in Windows) to the read files that we will be using (The appendix of this document contains the commands used to download these files directly from the EBI metagenomics site) Now, check they are there with: ls There should be six files in the directory, two for each sample in the dataset. e.g. K1_R1.fastq.gz The file ID has three components: K1 is the sample ID. R1 is for the first reads in the Illumina reads pair (R2 is for the set corresponding to the other end of the reads). fastq.gz tells us that this is a zipped FASTQ file. The sample labelling indicates the type treatment samples. The three samples are: K1: Fecal sample of individual of Korean diets K2: Fecal sample of individual of Korean diets W1: Fecal sample of individual of Western diets So, what do the R1 and R2 actually mean? With Illumina sequencing the vast majority of sequencing is paired end. i.e. DNA is first fragmented and both ends of each fragment are sequenced as shown here: This results in two sequences generated for each sequenced fragment: One reading in from the 3 end (R1) and the other reading in from the 5 end (R2). FASTQ is a sequence format much like FASTA, with the addition of quality scores. To see what a FASTQ file looks like, we can inspect the first few lines on one of our sequence files: zcat K1_R1.fastq.gz | head -n 4 | less -S The pipe symbol ( | ) is used to pass the output of one command as input to the next command. So, this command (1) shows the unzipped contents of the FASTQ file, (2) displays only the first 4 lines, and (3) displays them without wrapping lines (with S, for easy viewing). The lines displayed represent one FASTQ sequence entry, or one read of a read pair: The corresponding second read can be viewed by running the same command on K1_R2.fastq.gz. The first line is the read identifier, the second line is the sequence itself, the third line is a secondary header (which is usually left blank except for +) and the fourth line is the sequence quality score: For each base in the sequence, there is a corresponding quality encoded in this string of characters. To return to the command prompt, press q. Due to computational constraints, the files you have linked to are a subset of the original data (i.e. 1 million read pairs from each sample). At a later point in the tutorial, you will be asked to link to results derived from the full dataset for further processing. 4.2 Checking quality control We can generate and visualise various sequence data metrics for quality control purposes using the FastQC. Run FastQC on one of the files: fastqc K1_R1.fastq.gz Once completed, view the output (NB: The &amp; runs the command in the background, therefore allowing you to continue to run commands while Firefox is still open): firefox K1_R1_fastqc.html &amp; The FastQC report contains a number of metrics. The first graph shows the sequence quality across the length of the reads: Note how it decreases as the length of the read increases. While this is normal with Illumina sequencing, we can improve the situation a bit Briefly inspect the FastQC report for yourself  There are examples of typical (and atypical!) FastQC data in the appendix of this document Once you have finished looking, minimise the Firefox window. "],["05-Trimming_data.html", "Chapter 5 Quality control 5.1 Removing adapters and low quality bases 5.2 Rename the files 5.3 Inspect the trimmed data", " Chapter 5 Quality control Now that weve obtained the raw data and had a look at it, we should now clean it up. With any sequencing data, it is very important to ensure that you use the highest quality data possible: Rubbish goes in, rubbish comes out. There are two main methods employed to clean sequence data, and a third method specific to some metagenomic datasets. Remove low quality bases from the end of the reads. These are more likely to be incorrect, so are best trimmed off. Remove adapters. Sometimes sequencing adapters can be sequenced if the sequencing runs off the end of a fragment. Remove host sequences. If a metagenomic sample derives from a host species then it may be advisable to remove any reads associated with the host genome. Here, we do not need to do this, as the dataset contains barely any human genome sequences. 5.1 Removing adapters and low quality bases First go back to your home directory and create a new directory where we will clean the sequences up: cd .. This will move you one directory up, i.e. back to your home directory. Alternatively, you could use cd ~ which will take you to your home directory. This is a good idea if you ever get lost! mkdir 2-Trimmed cd 2-Trimmed You are now in your newly created directory. Here we will run Trim Galore! which carries out both of these steps. trim_galore --paired --quality 20 --stringency 4 \\ ../1-Raw/K1_R1.fastq.gz ../1-Raw/K1_R2.fastq.gz This is a longer command so weve split it across multiple commands (a \\ at the end of a line allows you to press return without running the command, meaning you can continue to add to that command. When this happens, the $ changes to a &gt;. Note that if you do use the \\ character, the next character immediately after it must be return. If you use \\ in the middle of a line without pressing return afterwards, it will break the command! This command will remove any low quality regions from the end of both reads in each read pair (quality score &lt; 20). Additionally, if it detects four or more bases of a sequencing adapter, it will trim that off too. We use the two read files for sample K1 as input, from the previous directory we were in. Run this command two more times, but for the other two samples (K2 and W1) 5.2 Rename the files Once that is complete if you run: ls you will notice that we have a new bunch of files created: 2 new read files for each sample along with a trimming report for each file trimmed. However, the new names are needlessly long. e.g. K1_R1_val_R1.fq.gz could be shortened to K1_R1.fq.gz. So, well rename all of the files with the mv command: mv K1_R1_val_1.fq.gz K1_R1.fq.gz mv K1_R2_val_2.fq.gz K1_R2.fq.gz mv K2_R1_val_1.fq.gz K2_R1.fq.gz mv K2_R2_val_2.fq.gz K2_R2.fq.gz mv W1_R1_val_1.fq.gz W1_R1.fq.gz mv W1_R2_val_2.fq.gz W1_R2.fq.gz Tip: If you want to edit and reuse previous commands, press the up arrow key. Briefly inspect the log files to see how the trimming went (e.g. K1_R1.fastq.gz_trimming_report.txt) 5.3 Inspect the trimmed data To see what difference the trimming made, run FastQC again on the trimmed output file K1_R1.fq.gz and view it. fastqc K1_R1.fq.gz firefox K1_R1_fastqc.html &amp; Inspect the FastQC report for yourself. How does it compare to the untrimmed data? Now that we have trimmed data, we can start the analyses! "]]
